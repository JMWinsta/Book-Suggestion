{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733760cc",
   "metadata": {},
   "source": [
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.tools import tool\n",
    "import random\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63ff6c",
   "metadata": {},
   "source": [
    "# Simulated book database\n",
    "book_database = {\n",
    "    \"Thinking, Fast and Slow\": {\"creativity\": 2, \"accuracy\": 5, \"knowledge\": 5},\n",
    "    \"The Alchemist\": {\"creativity\": 5, \"accuracy\": 2, \"knowledge\": 3},\n",
    "    \"Sapiens\": {\"creativity\": 4, \"accuracy\": 4, \"knowledge\": 5},\n",
    "    \"1984\": {\"creativity\": 3, \"accuracy\": 4, \"knowledge\": 4},\n",
    "    \"Harry Potter\": {\"creativity\": 5, \"accuracy\": 3, \"knowledge\": 3},\n",
    "}\n",
    "\n",
    "# Initial user state\n",
    "state = {\n",
    "    \"preferences\": {\"creativity\": 8, \"accuracy\": 4, \"knowledge\": 6},\n",
    "    \"recommended_book\": \"None\",\n",
    "    \"feedback\": \"0.0\",\n",
    "    \"weights\": {\"creativity\": 5.0, \"accuracy\": 5.0, \"knowledge\": 5.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb9cd1",
   "metadata": {},
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def recommend_book() -> str:\n",
    "    \"\"\"Recommend the best book based on weighted user preferences.\"\"\"\n",
    "    global state\n",
    "    weights = state[\"weights\"]\n",
    "    scores = {}\n",
    "    for book, traits in book_database.items():\n",
    "        score = sum(weights.get(k, 0) * traits.get(k, 0) for k in traits)\n",
    "        scores[book] = score\n",
    "    best_book = max(scores, key=scores.get)\n",
    "    state[\"recommended_book\"] = best_book\n",
    "    return f\"Recommended book: {best_book} based on weights {weights}\"\n",
    "\n",
    "@tool\n",
    "def simulate_feedback() -> str:\n",
    "    \"\"\"Simulate user feedback based on how well the recommended book aligns with preferences.\"\"\"\n",
    "    global state\n",
    "    book = state[\"recommended_book\"]\n",
    "    prefs = state[\"preferences\"]\n",
    "    traits = book_database.get(book, {})\n",
    "    alignment = sum(\n",
    "        1 if traits.get(k, 0) >= prefs.get(k, 5) else -1\n",
    "        for k in prefs\n",
    "    )\n",
    "    feedback = \"good\" if alignment >= 0 else \"bad\"\n",
    "    state[\"feedback\"] = feedback\n",
    "    return f\"User gave '{book}' a feedback: {feedback}\"\n",
    "\n",
    "@tool\n",
    "def update_weights() -> str:\n",
    "    \"\"\"Update weights based on feedback to improve future recommendations.\"\"\"\n",
    "    global state\n",
    "    feedback = state[\"feedback\"]\n",
    "    book = state[\"recommended_book\"]\n",
    "    traits = book_database[book]\n",
    "    adjustment = 1 if feedback == \"good\" else -1\n",
    "\n",
    "    for k in state[\"weights\"]:\n",
    "        delta = 0.1 * adjustment * traits.get(k, 0)\n",
    "        state[\"weights\"][k] += delta\n",
    "        state[\"weights\"][k] = max(0.0, min(10.0, state[\"weights\"][k]))\n",
    "    return f\"Updated weights: {state['weights']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c95b7a",
   "metadata": {},
   "source": [
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Load local Ollama LLM\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0.7)\n",
    "\n",
    "# Define tools with proper name and description\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=recommend_book,\n",
    "        name=\"RecommendBook\",\n",
    "        description=\"Recommend a book based on user preferences.\"\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=simulate_feedback,\n",
    "        name=\"SimulateFeedback\",\n",
    "        description=\"Simulate user feedback for a given recommendation.\"\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=update_weights,\n",
    "        name=\"UpdateWeights\",\n",
    "        description=\"Update the preference weights based on feedback.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create the agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f8c6d",
   "metadata": {},
   "source": [
    "# Run 3 rounds of book recommendation\n",
    "for i in range(3):\n",
    "    print(f\"\\n=== Round {i+1} ===\")\n",
    "\n",
    "    # Step 1: Prompt LLM to choose a book title\n",
    "    prompt = (\n",
    "        f\"User preferences: {state['preferences']}.\\n\"\n",
    "        f\"Choose ONE exact book title from: {', '.join(book_database.keys())}.\\n\"\n",
    "        \"Reply with ONLY the book title. No explanations. No extra words.\"\n",
    "    )\n",
    "    response = llm.invoke(prompt).content.strip()\n",
    "\n",
    "    # Step 2: Match valid title\n",
    "    matched_title = next(\n",
    "        (title for title in book_database if title.lower() in response.lower()),\n",
    "        None\n",
    "    )\n",
    "    if not matched_title:\n",
    "        print(\"[Error] Invalid book title returned by LLM:\", response)\n",
    "        continue\n",
    "\n",
    "    state[\"recommended_book\"] = matched_title\n",
    "\n",
    "    # Step 3: Short explanation\n",
    "    traits = book_database[matched_title]\n",
    "    explain_prompt = (\n",
    "        f\"User prefs: {state['preferences']}. Book traits: {traits}. \"\n",
    "        f\"Why is '{matched_title}' a good match? Reply with ONE short sentence ONLY. No <think>. No reasoning steps.\"\n",
    "    )\n",
    "    explanation = llm.invoke(explain_prompt).content.strip()\n",
    "\n",
    "    # Step 4: Print result\n",
    "    print(f\"[Final Recommendation] {matched_title}\")\n",
    "    print(f\"[Reason] {explanation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
